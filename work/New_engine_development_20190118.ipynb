{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ToDo\n",
    "    + Evaluationの実装 : ongoing (-1/20)\n",
    "    + TrainManagerの改良 : ongoing (-1/31)\n",
    "    + Metricsの定義 : not start (1/24-1/25)\n",
    "    + Eventの追加 : not start (1/25-1/31)\n",
    "        - EarlyStopping\n",
    "        - ModelSave\n",
    "    + RL : not start (2/1-2/7)\n",
    "    + LRScheduller : not start (1/26-1/31)\n",
    "    + GPU : not start ()\n",
    "    + DataParalell : not start ()\n",
    "    + ModelParalell : not start ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T23:57:44.774530Z",
     "start_time": "2020-03-16T23:57:44.704620Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T23:57:44.817999Z",
     "start_time": "2020-03-16T23:57:44.808320Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T23:57:48.461363Z",
     "start_time": "2020-03-16T23:57:47.638597Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--mnist-path\")\n",
    "args = parser.parse_args(args=[\"--mnist-path\", \"/home/noriaki/MachineLearning/Datasets/\"])\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(10)\n",
    "from develop.flash.debug import get_data_loaders\n",
    "mnist_path = args.mnist_path\n",
    "train_loader, val_loader = get_data_loaders(train_batch_size=16,\n",
    "                                            val_batch_size=16, mnist_path=mnist_path,\n",
    "                                            train_dataset_size=np.random.randint(0,60000,60),\n",
    "                                            val_dataset_size=np.random.randint(0,10000,23), download=True)\n",
    "\n",
    "from develop.flash.dataloader import get_sampled_loader\n",
    "eval_train_loader = get_sampled_loader(train_loader, num_samples=35)\n",
    "\n",
    "\n",
    "from develop.flash.debug import TestNet\n",
    "model = TestNet()\n",
    "\n",
    "from develop.flash.optimizers import get_optimzier\n",
    "\n",
    "optimizer_info = {\n",
    "    \"name\" : \"SGD\",\n",
    "    \"args\" : {\n",
    "        \"lr\" : 0.01,\n",
    "        \"momentum\" : 0.5    \n",
    "    },\n",
    "}\n",
    "\n",
    "optimizer = get_optimzier(optimizer_info, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T23:57:49.283359Z",
     "start_time": "2020-03-16T23:57:49.224931Z"
    }
   },
   "outputs": [],
   "source": [
    "from develop.flash.utils import wrap_metrics, get_y_values\n",
    "import torch.nn as nn\n",
    "\n",
    "loss_ = wrap_metrics(nn.NLLLoss(), get_y_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T23:57:49.652306Z",
     "start_time": "2020-03-16T23:57:49.607490Z"
    }
   },
   "outputs": [],
   "source": [
    "from flash.core.data_utils import DataGateway, DataWarehouse, TrainDataServer\n",
    "from flash.core.process import ModelFlowProcess, Process, ModelFlowManager, EventManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T08:41:56.419983Z",
     "start_time": "2020-01-25T08:41:56.396637Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-813f4a2febdc>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-813f4a2febdc>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    }\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# new config ???\n",
    "{\n",
    "    \"data-gateway\" : {\n",
    "        \"num_batch_division\" : 1,\n",
    "        \"max_batch\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T23:57:53.539452Z",
     "start_time": "2020-03-16T23:57:53.487053Z"
    }
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"train\" : {\n",
    "        \"batch_size\" : 32\n",
    "    },\n",
    "    \"data\" : {\n",
    "        \"input_transform\" : lambda x:{'x':x[0], 'y':x[1]}\n",
    "    },\n",
    "    \"others\" : {\n",
    "        \"grad_accumulation_steps\" : 1,\n",
    "        \"eval_batch_size\" : 32\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T23:57:55.274719Z",
     "start_time": "2020-03-16T23:57:55.206926Z"
    }
   },
   "outputs": [],
   "source": [
    "# temporal\n",
    "\"\"\"\n",
    "    configのデフォルト値はどうする？\n",
    "\"\"\"\n",
    "\n",
    "def create_default_data_server(config):\n",
    "    update_data_gateway_args = dict(\n",
    "        default_input_size = config['train']['batch_size'],\n",
    "        num_batch_division = config['others'].get('grad_accumulation_steps', 1),\n",
    "        input_transform = config['data'].get('input_transform', None)\n",
    "    )\n",
    "    eval_data_gateway_args = dict(\n",
    "        default_input_size = config['others']['eval_batch_size'],\n",
    "        input_transform = config['data'].get('input_transform', None)\n",
    "    )\n",
    "    \n",
    "    update_data_gateway = DataGateway(**update_data_gateway_args)\n",
    "    eval_data_gateway = DataGateway(**eval_data_gateway_args)\n",
    "    data_warehouse = DataWarehouse()\n",
    "    update_data_server = TrainDataServer(data_gateway=update_data_gateway, data_warehouse=data_warehouse)\n",
    "    eval_data_server = TrainDataServer(data_gateway=eval_data_gateway, data_warehouse=data_warehouse)\n",
    "    return { 'update' : update_data_server, 'evaluate' : eval_data_server }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T07:50:32.678136Z",
     "start_time": "2020-01-19T07:50:32.603919Z"
    }
   },
   "source": [
    "dg = DataGateway(default_input_size=10, max_batch_size=10, num_batch_division=2, input_transform=lambda x:{'x':x[0], 'y':x[1]})\n",
    "\n",
    "dw = DataWarehouse()\n",
    "\n",
    "ds = TrainDataServer(data_gateway=dg, data_warehouse=dw, data_loader=eval_train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T14:17:35.897059Z",
     "start_time": "2020-01-23T14:17:35.865132Z"
    }
   },
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T15:05:02.216979Z",
     "start_time": "2020-01-23T15:05:02.130217Z"
    }
   },
   "outputs": [],
   "source": [
    "from flash.core.process import ProcessManager\n",
    "class EvalModelFlowManager(ProcessManager):\n",
    "    def __init__(self, data_server, event_manager):\n",
    "        self.data_server = data_server\n",
    "        #self.event_manager = event_manager\n",
    "        self.process_info = OrderedDict()\n",
    "        self.state = {}# class State in the future\n",
    "        \n",
    "        self.state[\"global/epoch\"] = 1\n",
    "        self.state[\"global/iteration\"] = 1\n",
    "    \n",
    "    def register_process(self, process, process_name=None, process_config={}):\n",
    "        # type name : str\n",
    "        assert hasattr(process,'run')\n",
    "\n",
    "        if process_name is None:\n",
    "            process_name = f\"process-{len(self.process_info)+1}\"\n",
    "        \n",
    "        if hasattr(process, 'name'):\n",
    "            assert process_name == getattr(process, 'name', process_name)\n",
    "        else:\n",
    "            setattr(process, 'name', process_name)\n",
    "        assert process_name not in self.process_info.keys()\n",
    "        \n",
    "        # (process, process_config)\n",
    "        self.process_info.update({process_name : (process, process_config)})\n",
    "        \n",
    "    def register_multiple_processes(self, process_info):\n",
    "        raise NotImplementedError\n",
    "        # assert hasattr(process,run)\n",
    "        #assert process_name not in self.process_info.keys()\n",
    "        \n",
    "        # (process, process_config)\n",
    "        # may change into list from dict because Process class has its name ...\n",
    "        self.process_info.update(process_info)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return enumerate(self.process_info.values(), 1)\n",
    "        \n",
    "    def _reset_state(self):\n",
    "        self.state[\"run/epoch\"] = 1\n",
    "        self.state[\"run/iteration\"] = 1\n",
    "    \n",
    "    def run(self, state=None, process_config=dict(num_epochs=1)):\n",
    "        num_epochs = process_config['num_epochs']\n",
    "        data_loader_name = process_config.get('data_loader_name', None)## eval\n",
    "\n",
    "        # ToDo: Consider the training restart case\n",
    "        self._reset_state()\n",
    "        state = self.state\n",
    "        \n",
    "        self._set_data_server()\n",
    "        data_server = self.data_server\n",
    "        if data_loader_name is not None:### eval\n",
    "            data_server.set_data_loader(data_loader_name)### eval\n",
    "        #event_manager = self.event_manager\n",
    "        #event_manager._set_state(state)\n",
    "        \n",
    "        #event_manager.fire_events(\"run-start\")\n",
    "        for epoch in range(1, num_epochs+1):\n",
    "            #event_manager.fire_events(\"epoch-start\")\n",
    "            \n",
    "            for iteration in data_server:\n",
    "                #event_manager.fire_events(\"iter-start\")\n",
    "                #self.state.output = self._process_function(self, self.state.batch)\n",
    "\n",
    "                for N, (process, process_config_) in self:\n",
    "                    process_config_ = {**process_config, **process_config_}\n",
    "                    process.run(state=state, process_config=process_config_)\n",
    "                #event_manager.fire_events(\"iter-end\")\n",
    "                #results = data_server.get_results()\n",
    "                self.state[\"run/iteration\"] = iteration\n",
    "                self.state[\"global/iteration\"] += 1\n",
    "                \n",
    "            #event_manager.fire_events(\"epoch-end\")\n",
    "            self.state[\"run/epoch\"] = epoch\n",
    "            self.state[\"global/epoch\"] += 1\n",
    "            # evnet on exceptions\n",
    "        #event_manager.fire_events(\"run-end\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T08:43:05.617487Z",
     "start_time": "2020-01-25T08:43:05.589935Z"
    }
   },
   "outputs": [],
   "source": [
    "# new version : TrainManager\n",
    "\n",
    "class TrainManager():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def set_config(self, config: dict):\n",
    "        self.config = config\n",
    "        #self.check()\n",
    "        self.config['objects'] = {\n",
    "            'update_process_list' : [],\n",
    "            'evaluate_process_list' : [],\n",
    "        }#temporal\n",
    "\n",
    "    def setup(self):\n",
    "        config = self.config\n",
    "        data = config['objects']['data']\n",
    "        \n",
    "        data_server_set = create_default_data_server(config)\n",
    "        event_manager = EventManager(data_server=None)\n",
    "        update_process_manager = ModelFlowManager(data_server=data_server_set['update'], event_manager=event_manager)\n",
    "        evaluate_process_manager = ModelFlowManager(data_server=data_server_set['evaluate'], event_manager=None)\n",
    "        \n",
    "        self.data_server_set = data_server_set\n",
    "        self.event_manager = event_manager\n",
    "        self.update_process_manager = update_process_manager\n",
    "        self.evaluate_process_manager = evaluate_process_manager\n",
    "        \n",
    "        for process in self.update_process_list:\n",
    "            update_process_manager.register_process(process)\n",
    "        for process in self.evaluate_process_list:\n",
    "            evaluate_process_manager.register_process(process)\n",
    "        event_manager.register_event(\"epoch-end\", evaluate_process_manager, {'num_epochs' : 1, 'data_loader_name' : 'eval_train', 'output_save_info' : {'Save_all':True}})\n",
    "        event_manager.register_event(\"epoch-end\", evaluate_process_manager, {'num_epochs' : 1, 'data_loader_name' : 'val', 'output_save_info' : {'Save_all':True}})\n",
    "        \n",
    "        data_server_set['update'].register_data_loader({'train':data['train_loader']})\n",
    "        data_server_set['evaluate'].register_data_loader({'eval_train':data['eval_train_loader'], 'val':data['val_loader']})\n",
    "\n",
    "    def add_process(self, process, mode='update'):\n",
    "        assert mode in ['update', 'evaluate']\n",
    "        #self.process_manager.register_process(process)\n",
    "        \n",
    "        config = self.config\n",
    "        if isinstance(process, list):\n",
    "            raise NotImplementedError\n",
    "        elif isinstance(process, dict):\n",
    "            raise NotImplementedError\n",
    "        else:\n",
    "            process_list = [process]\n",
    "            # diagnosis_process(process)\n",
    "        \n",
    "        if mode == 'update':\n",
    "            update_process_list = config['objects']['update_process_list']\n",
    "            update_process_list.extend(process_list)\n",
    "        elif mode == 'evaluate':\n",
    "            evaluate_process_list = config['objects']['evaluate_process_list']\n",
    "            evaluate_process_list.extend(process_list)\n",
    "    \n",
    "    @property\n",
    "    def update_process_list(self):\n",
    "        return self.config['objects']['update_process_list']\n",
    "\n",
    "    @property\n",
    "    def evaluate_process_list(self):\n",
    "        return self.config['objects']['evaluate_process_list']\n",
    "\n",
    "    def set_dataloader(self, train_loader, val_loader, eval_train_loader=None):\n",
    "        config = self.config\n",
    "        data = {\n",
    "            'train_loader' : train_loader,\n",
    "            'val_loader' : val_loader\n",
    "        }\n",
    "        if eval_train_loader is not None:\n",
    "            data.update({'eval_train_loader' : eval_train_loader})\n",
    "        config[\"objects\"].update({ 'data' : data })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T08:45:19.501009Z",
     "start_time": "2020-01-25T08:45:19.447210Z"
    }
   },
   "outputs": [],
   "source": [
    "from flash.core.data_utils import TrainDataServer\n",
    "from flash.core.process import ModelFlowProcess, ModelFlowManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T08:45:19.581306Z",
     "start_time": "2020-01-25T08:45:19.565547Z"
    }
   },
   "outputs": [],
   "source": [
    "update_process = ModelFlowProcess(model, loss_fn=loss_, optimizer=optimizer, mode='train', process_name='up')\n",
    "eval_process = ModelFlowProcess(model, mode='eval', process_name='ev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T08:45:19.760559Z",
     "start_time": "2020-01-25T08:45:19.714001Z"
    }
   },
   "outputs": [],
   "source": [
    "tm = TrainManager()\n",
    "tm.set_config(config)\n",
    "tm.set_dataloader(train_loader=train_loader, val_loader=val_loader, eval_train_loader=eval_train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T08:45:19.872403Z",
     "start_time": "2020-01-25T08:45:19.844508Z"
    }
   },
   "outputs": [],
   "source": [
    "tm.add_process(update_process, mode='update')\n",
    "tm.add_process(eval_process, mode='evaluate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T08:45:19.995820Z",
     "start_time": "2020-01-25T08:45:19.973666Z"
    }
   },
   "outputs": [],
   "source": [
    "tm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T08:45:20.123234Z",
     "start_time": "2020-01-25T08:45:20.104455Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({}, {'global/epoch': 1, 'global/iteration': 1})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = tm.data_server_set['update']\n",
    "ds.set_data_loader(key='train')\n",
    "\n",
    "ds.results, tm.update_process_manager.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T08:45:20.394161Z",
     "start_time": "2020-01-25T08:45:20.231079Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 {'num_epochs': 1} {}\n",
      "up train {'num_epochs': 1}\n",
      "1 {'num_epochs': 1} {}\n",
      "up train {'num_epochs': 1}\n",
      "1 {'num_epochs': 1} {}\n",
      "up train {'num_epochs': 1}\n",
      "1 {'num_epochs': 1} {}\n",
      "up train {'num_epochs': 1}\n",
      "1 {'num_epochs': 1, 'data_loader_name': 'eval_train', 'output_save_info': {'Save_all': True}} {}\n",
      "ev eval_train {'num_epochs': 1, 'data_loader_name': 'eval_train', 'output_save_info': {'Save_all': True}}\n",
      "1 {'num_epochs': 1, 'data_loader_name': 'eval_train', 'output_save_info': {'Save_all': True}} {}\n",
      "ev eval_train {'num_epochs': 1, 'data_loader_name': 'eval_train', 'output_save_info': {'Save_all': True}}\n",
      "1 {'num_epochs': 1, 'data_loader_name': 'eval_train', 'output_save_info': {'Save_all': True}} {}\n",
      "ev eval_train {'num_epochs': 1, 'data_loader_name': 'eval_train', 'output_save_info': {'Save_all': True}}\n",
      "1 {'num_epochs': 1, 'data_loader_name': 'val', 'output_save_info': {'Save_all': True}} {}\n",
      "ev val {'num_epochs': 1, 'data_loader_name': 'val', 'output_save_info': {'Save_all': True}}\n",
      "1 {'num_epochs': 1, 'data_loader_name': 'val', 'output_save_info': {'Save_all': True}} {}\n",
      "ev val {'num_epochs': 1, 'data_loader_name': 'val', 'output_save_info': {'Save_all': True}}\n"
     ]
    }
   ],
   "source": [
    "tm.update_process_manager.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T08:46:22.377700Z",
     "start_time": "2020-01-25T08:46:22.293481Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function flash.core.data_utils.DataWarehouse._reset.<locals>.<lambda>()>,\n",
       "            {'currnt/outputs': [{'y': tensor([[-2.3958, -2.5058, -2.4579, -2.0148, -2.3350, -2.2528, -2.3071, -2.3932,\n",
       "                        -2.1541, -2.3076],\n",
       "                       [-2.2914, -2.4203, -2.4016, -2.1853, -2.3184, -2.2392, -2.3318, -2.3759,\n",
       "                        -2.2049, -2.2860],\n",
       "                       [-2.3856, -2.4869, -2.4721, -1.9957, -2.3032, -2.2534, -2.3143, -2.3649,\n",
       "                        -2.1854, -2.3616],\n",
       "                       [-2.3482, -2.4150, -2.4081, -2.0906, -2.3258, -2.3125, -2.2777, -2.3726,\n",
       "                        -2.2008, -2.3198],\n",
       "                       [-2.3275, -2.5099, -2.5066, -2.0196, -2.3333, -2.2271, -2.3286, -2.3570,\n",
       "                        -2.1708, -2.3443],\n",
       "                       [-2.3580, -2.4298, -2.4748, -2.0837, -2.2764, -2.2359, -2.3355, -2.3533,\n",
       "                        -2.1770, -2.3650],\n",
       "                       [-2.3249, -2.4509, -2.5059, -2.0117, -2.3014, -2.2562, -2.3456, -2.4235,\n",
       "                        -2.2201, -2.2754],\n",
       "                       [-2.4154, -2.4763, -2.4381, -2.1225, -2.3087, -2.2559, -2.2550, -2.2869,\n",
       "                        -2.1698, -2.3567],\n",
       "                       [-2.3611, -2.4791, -2.4545, -2.0923, -2.3321, -2.2939, -2.2856, -2.3680,\n",
       "                        -2.1486, -2.2772],\n",
       "                       [-2.3379, -2.4809, -2.4355, -2.0778, -2.3436, -2.2666, -2.3039, -2.3370,\n",
       "                        -2.1636, -2.3434],\n",
       "                       [-2.3958, -2.5058, -2.4579, -2.0148, -2.3350, -2.2528, -2.3071, -2.3932,\n",
       "                        -2.1541, -2.3076],\n",
       "                       [-2.3934, -2.4545, -2.4241, -2.0578, -2.3246, -2.2180, -2.3036, -2.3821,\n",
       "                        -2.2034, -2.3315],\n",
       "                       [-2.3611, -2.4791, -2.4545, -2.0923, -2.3321, -2.2939, -2.2856, -2.3680,\n",
       "                        -2.1486, -2.2772],\n",
       "                       [-2.3275, -2.5099, -2.5066, -2.0196, -2.3333, -2.2271, -2.3286, -2.3570,\n",
       "                        -2.1708, -2.3443],\n",
       "                       [-2.3632, -2.4621, -2.4937, -2.0005, -2.3105, -2.2696, -2.3215, -2.3748,\n",
       "                        -2.2129, -2.3062],\n",
       "                       [-2.4134, -2.5082, -2.3999, -2.0681, -2.3562, -2.2761, -2.2146, -2.3694,\n",
       "                        -2.1648, -2.3335]])},\n",
       "              {'y': tensor([[-2.3739, -2.5023, -2.4478, -2.0934, -2.3553, -2.2575, -2.2315, -2.3253,\n",
       "                        -2.1686, -2.3404],\n",
       "                       [-2.3959, -2.3986, -2.3859, -2.1601, -2.3493, -2.2772, -2.2592, -2.2974,\n",
       "                        -2.1964, -2.3374],\n",
       "                       [-2.3282, -2.4755, -2.4126, -2.1037, -2.3485, -2.2706, -2.2913, -2.3190,\n",
       "                        -2.1767, -2.3525],\n",
       "                       [-2.3501, -2.4683, -2.4690, -2.0552, -2.3316, -2.3057, -2.2423, -2.3711,\n",
       "                        -2.1860, -2.3190],\n",
       "                       [-2.3353, -2.4602, -2.4499, -2.0436, -2.3678, -2.2300, -2.3234, -2.3715,\n",
       "                        -2.1831, -2.3357],\n",
       "                       [-2.3353, -2.4602, -2.4499, -2.0436, -2.3678, -2.2300, -2.3234, -2.3715,\n",
       "                        -2.1831, -2.3357],\n",
       "                       [-2.3426, -2.4539, -2.4486, -2.0420, -2.3086, -2.3076, -2.2925, -2.3724,\n",
       "                        -2.2150, -2.3082],\n",
       "                       [-2.4068, -2.5091, -2.4665, -2.0581, -2.3185, -2.2682, -2.2416, -2.3671,\n",
       "                        -2.1859, -2.2864],\n",
       "                       [-2.3959, -2.3986, -2.3859, -2.1601, -2.3493, -2.2772, -2.2592, -2.2974,\n",
       "                        -2.1964, -2.3374],\n",
       "                       [-2.3197, -2.4472, -2.4303, -2.1364, -2.3600, -2.2885, -2.3072, -2.3245,\n",
       "                        -2.1845, -2.2698],\n",
       "                       [-2.3532, -2.4828, -2.4554, -2.0480, -2.3436, -2.2673, -2.2690, -2.3443,\n",
       "                        -2.1731, -2.3657],\n",
       "                       [-2.3493, -2.4796, -2.4353, -2.0305, -2.3077, -2.2623, -2.3439, -2.3547,\n",
       "                        -2.2072, -2.3283],\n",
       "                       [-2.3853, -2.4799, -2.4069, -2.1057, -2.3456, -2.2692, -2.2789, -2.3250,\n",
       "                        -2.1664, -2.3191],\n",
       "                       [-2.3403, -2.4634, -2.4552, -2.0877, -2.2707, -2.3301, -2.3006, -2.3571,\n",
       "                        -2.1515, -2.3330],\n",
       "                       [-2.2928, -2.4335, -2.4309, -2.1248, -2.3072, -2.2570, -2.2991, -2.3609,\n",
       "                        -2.2027, -2.3594],\n",
       "                       [-2.3853, -2.4799, -2.4069, -2.1057, -2.3456, -2.2692, -2.2789, -2.3250,\n",
       "                        -2.1664, -2.3191]])},\n",
       "              {'y': tensor([[-2.3531, -2.4917, -2.4738, -2.0238, -2.3512, -2.2524, -2.2840, -2.3988,\n",
       "                        -2.1973, -2.2874],\n",
       "                       [-2.3505, -2.4847, -2.4389, -2.0674, -2.3594, -2.2317, -2.2993, -2.3777,\n",
       "                        -2.1806, -2.3060],\n",
       "                       [-2.3611, -2.4791, -2.4545, -2.0923, -2.3321, -2.2939, -2.2856, -2.3680,\n",
       "                        -2.1486, -2.2772]])},\n",
       "              {'y': tensor([[-2.3201, -2.4554, -2.4213, -2.0910, -2.2791, -2.2492, -2.3681, -2.4257,\n",
       "                        -2.1796, -2.2974],\n",
       "                       [-2.3371, -2.4291, -2.4053, -2.1009, -2.3073, -2.2389, -2.3410, -2.4068,\n",
       "                        -2.2030, -2.3047],\n",
       "                       [-2.3705, -2.5254, -2.4294, -2.0546, -2.3464, -2.3065, -2.3017, -2.3674,\n",
       "                        -2.1557, -2.2504],\n",
       "                       [-2.3258, -2.4509, -2.4082, -2.1564, -2.3564, -2.2746, -2.2796, -2.3103,\n",
       "                        -2.1989, -2.2998],\n",
       "                       [-2.3459, -2.4965, -2.3969, -2.1508, -2.2912, -2.3289, -2.2502, -2.3370,\n",
       "                        -2.1697, -2.3053],\n",
       "                       [-2.3350, -2.4853, -2.4832, -2.0883, -2.3179, -2.3080, -2.2583, -2.3721,\n",
       "                        -2.1825, -2.2634],\n",
       "                       [-2.3630, -2.4727, -2.4192, -2.1213, -2.3145, -2.2946, -2.2718, -2.3065,\n",
       "                        -2.1744, -2.3370],\n",
       "                       [-2.3918, -2.4286, -2.4023, -2.0753, -2.3680, -2.2472, -2.2901, -2.3122,\n",
       "                        -2.2232, -2.3390],\n",
       "                       [-2.3884, -2.4643, -2.4158, -2.0082, -2.3498, -2.2827, -2.3484, -2.3738,\n",
       "                        -2.1804, -2.2968],\n",
       "                       [-2.3740, -2.3992, -2.4114, -2.1247, -2.3529, -2.2650, -2.3341, -2.3354,\n",
       "                        -2.1912, -2.2772],\n",
       "                       [-2.2930, -2.4552, -2.4512, -2.1154, -2.2899, -2.2449, -2.3218, -2.3848,\n",
       "                        -2.1815, -2.3421],\n",
       "                       [-2.3556, -2.5127, -2.4694, -2.0139, -2.3107, -2.2590, -2.3557, -2.3944,\n",
       "                        -2.1455, -2.3094],\n",
       "                       [-2.3789, -2.4998, -2.4462, -2.0183, -2.3256, -2.2694, -2.2933, -2.3754,\n",
       "                        -2.1799, -2.3261],\n",
       "                       [-2.3371, -2.4566, -2.4613, -2.0310, -2.2825, -2.2494, -2.3623, -2.3775,\n",
       "                        -2.2252, -2.3168],\n",
       "                       [-2.3288, -2.4464, -2.4001, -2.0937, -2.3079, -2.2463, -2.3390, -2.4095,\n",
       "                        -2.1997, -2.3060],\n",
       "                       [-2.3295, -2.4659, -2.4704, -2.0716, -2.2984, -2.2808, -2.3473, -2.3853,\n",
       "                        -2.1945, -2.2494]])},\n",
       "              {'y': tensor([[-2.4061, -2.4542, -2.4556, -2.0549, -2.3512, -2.2612, -2.2506, -2.3556,\n",
       "                        -2.2046, -2.3023],\n",
       "                       [-2.3905, -2.5027, -2.4727, -2.0805, -2.3102, -2.2485, -2.2693, -2.3588,\n",
       "                        -2.1696, -2.2988],\n",
       "                       [-2.3351, -2.5301, -2.4442, -2.0502, -2.3100, -2.2706, -2.2987, -2.3595,\n",
       "                        -2.1694, -2.3388],\n",
       "                       [-2.3985, -2.4750, -2.4391, -2.0474, -2.3296, -2.2463, -2.2828, -2.3691,\n",
       "                        -2.1683, -2.3476],\n",
       "                       [-2.3129, -2.4178, -2.3709, -2.1771, -2.3386, -2.2974, -2.2822, -2.3551,\n",
       "                        -2.2288, -2.2674],\n",
       "                       [-2.3654, -2.5186, -2.4550, -2.1059, -2.3548, -2.3352, -2.1972, -2.3395,\n",
       "                        -2.1218, -2.3136],\n",
       "                       [-2.3230, -2.4411, -2.4022, -2.1733, -2.2960, -2.3512, -2.2472, -2.3731,\n",
       "                        -2.1822, -2.2726]])}]})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.data_warehouse.data_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T08:47:54.252020Z",
     "start_time": "2020-01-25T08:47:54.194096Z"
    }
   },
   "outputs": [],
   "source": [
    "from flash.utils import _concat_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T10:51:13.175381Z",
     "start_time": "2020-01-25T10:51:13.154692Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp = ds.data_warehouse.data_stack['currnt/outputs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T10:51:23.744808Z",
     "start_time": "2020-01-25T10:51:23.707114Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 10])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[0]['y'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T08:49:41.261584Z",
     "start_time": "2020-01-25T08:49:41.234809Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#y = _concat_results(ds.data_warehouse.data_stack['current/outputs'])\n",
    "y = _concat_results(ds.data_warehouse.data_stack['currnt/outputs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T08:49:53.090165Z",
     "start_time": "2020-01-25T08:49:53.035788Z"
    }
   },
   "outputs": [],
   "source": [
    "y = y['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T08:49:55.634841Z",
     "start_time": "2020-01-25T08:49:55.555752Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3958, -2.5058, -2.4579, -2.0148, -2.3350, -2.2528, -2.3071, -2.3932,\n",
       "         -2.1541, -2.3076],\n",
       "        [-2.2914, -2.4203, -2.4016, -2.1853, -2.3184, -2.2392, -2.3318, -2.3759,\n",
       "         -2.2049, -2.2860],\n",
       "        [-2.3856, -2.4869, -2.4721, -1.9957, -2.3032, -2.2534, -2.3143, -2.3649,\n",
       "         -2.1854, -2.3616],\n",
       "        [-2.3482, -2.4150, -2.4081, -2.0906, -2.3258, -2.3125, -2.2777, -2.3726,\n",
       "         -2.2008, -2.3198],\n",
       "        [-2.3275, -2.5099, -2.5066, -2.0196, -2.3333, -2.2271, -2.3286, -2.3570,\n",
       "         -2.1708, -2.3443],\n",
       "        [-2.3580, -2.4298, -2.4748, -2.0837, -2.2764, -2.2359, -2.3355, -2.3533,\n",
       "         -2.1770, -2.3650],\n",
       "        [-2.3249, -2.4509, -2.5059, -2.0117, -2.3014, -2.2562, -2.3456, -2.4235,\n",
       "         -2.2201, -2.2754],\n",
       "        [-2.4154, -2.4763, -2.4381, -2.1225, -2.3087, -2.2559, -2.2550, -2.2869,\n",
       "         -2.1698, -2.3567],\n",
       "        [-2.3611, -2.4791, -2.4545, -2.0923, -2.3321, -2.2939, -2.2856, -2.3680,\n",
       "         -2.1486, -2.2772],\n",
       "        [-2.3379, -2.4809, -2.4355, -2.0778, -2.3436, -2.2666, -2.3039, -2.3370,\n",
       "         -2.1636, -2.3434],\n",
       "        [-2.3958, -2.5058, -2.4579, -2.0148, -2.3350, -2.2528, -2.3071, -2.3932,\n",
       "         -2.1541, -2.3076],\n",
       "        [-2.3934, -2.4545, -2.4241, -2.0578, -2.3246, -2.2180, -2.3036, -2.3821,\n",
       "         -2.2034, -2.3315],\n",
       "        [-2.3611, -2.4791, -2.4545, -2.0923, -2.3321, -2.2939, -2.2856, -2.3680,\n",
       "         -2.1486, -2.2772],\n",
       "        [-2.3275, -2.5099, -2.5066, -2.0196, -2.3333, -2.2271, -2.3286, -2.3570,\n",
       "         -2.1708, -2.3443],\n",
       "        [-2.3632, -2.4621, -2.4937, -2.0005, -2.3105, -2.2696, -2.3215, -2.3748,\n",
       "         -2.2129, -2.3062],\n",
       "        [-2.4134, -2.5082, -2.3999, -2.0681, -2.3562, -2.2761, -2.2146, -2.3694,\n",
       "         -2.1648, -2.3335],\n",
       "        [-2.3739, -2.5023, -2.4478, -2.0934, -2.3553, -2.2575, -2.2315, -2.3253,\n",
       "         -2.1686, -2.3404],\n",
       "        [-2.3959, -2.3986, -2.3859, -2.1601, -2.3493, -2.2772, -2.2592, -2.2974,\n",
       "         -2.1964, -2.3374],\n",
       "        [-2.3282, -2.4755, -2.4126, -2.1037, -2.3485, -2.2706, -2.2913, -2.3190,\n",
       "         -2.1767, -2.3525],\n",
       "        [-2.3501, -2.4683, -2.4690, -2.0552, -2.3316, -2.3057, -2.2423, -2.3711,\n",
       "         -2.1860, -2.3190],\n",
       "        [-2.3353, -2.4602, -2.4499, -2.0436, -2.3678, -2.2300, -2.3234, -2.3715,\n",
       "         -2.1831, -2.3357],\n",
       "        [-2.3353, -2.4602, -2.4499, -2.0436, -2.3678, -2.2300, -2.3234, -2.3715,\n",
       "         -2.1831, -2.3357],\n",
       "        [-2.3426, -2.4539, -2.4486, -2.0420, -2.3086, -2.3076, -2.2925, -2.3724,\n",
       "         -2.2150, -2.3082],\n",
       "        [-2.4068, -2.5091, -2.4665, -2.0581, -2.3185, -2.2682, -2.2416, -2.3671,\n",
       "         -2.1859, -2.2864],\n",
       "        [-2.3959, -2.3986, -2.3859, -2.1601, -2.3493, -2.2772, -2.2592, -2.2974,\n",
       "         -2.1964, -2.3374],\n",
       "        [-2.3197, -2.4472, -2.4303, -2.1364, -2.3600, -2.2885, -2.3072, -2.3245,\n",
       "         -2.1845, -2.2698],\n",
       "        [-2.3532, -2.4828, -2.4554, -2.0480, -2.3436, -2.2673, -2.2690, -2.3443,\n",
       "         -2.1731, -2.3657],\n",
       "        [-2.3493, -2.4796, -2.4353, -2.0305, -2.3077, -2.2623, -2.3439, -2.3547,\n",
       "         -2.2072, -2.3283],\n",
       "        [-2.3853, -2.4799, -2.4069, -2.1057, -2.3456, -2.2692, -2.2789, -2.3250,\n",
       "         -2.1664, -2.3191],\n",
       "        [-2.3403, -2.4634, -2.4552, -2.0877, -2.2707, -2.3301, -2.3006, -2.3571,\n",
       "         -2.1515, -2.3330],\n",
       "        [-2.2928, -2.4335, -2.4309, -2.1248, -2.3072, -2.2570, -2.2991, -2.3609,\n",
       "         -2.2027, -2.3594],\n",
       "        [-2.3853, -2.4799, -2.4069, -2.1057, -2.3456, -2.2692, -2.2789, -2.3250,\n",
       "         -2.1664, -2.3191],\n",
       "        [-2.3531, -2.4917, -2.4738, -2.0238, -2.3512, -2.2524, -2.2840, -2.3988,\n",
       "         -2.1973, -2.2874],\n",
       "        [-2.3505, -2.4847, -2.4389, -2.0674, -2.3594, -2.2317, -2.2993, -2.3777,\n",
       "         -2.1806, -2.3060],\n",
       "        [-2.3611, -2.4791, -2.4545, -2.0923, -2.3321, -2.2939, -2.2856, -2.3680,\n",
       "         -2.1486, -2.2772],\n",
       "        [-2.3201, -2.4554, -2.4213, -2.0910, -2.2791, -2.2492, -2.3681, -2.4257,\n",
       "         -2.1796, -2.2974],\n",
       "        [-2.3371, -2.4291, -2.4053, -2.1009, -2.3073, -2.2389, -2.3410, -2.4068,\n",
       "         -2.2030, -2.3047],\n",
       "        [-2.3705, -2.5254, -2.4294, -2.0546, -2.3464, -2.3065, -2.3017, -2.3674,\n",
       "         -2.1557, -2.2504],\n",
       "        [-2.3258, -2.4509, -2.4082, -2.1564, -2.3564, -2.2746, -2.2796, -2.3103,\n",
       "         -2.1989, -2.2998],\n",
       "        [-2.3459, -2.4965, -2.3969, -2.1508, -2.2912, -2.3289, -2.2502, -2.3370,\n",
       "         -2.1697, -2.3053],\n",
       "        [-2.3350, -2.4853, -2.4832, -2.0883, -2.3179, -2.3080, -2.2583, -2.3721,\n",
       "         -2.1825, -2.2634],\n",
       "        [-2.3630, -2.4727, -2.4192, -2.1213, -2.3145, -2.2946, -2.2718, -2.3065,\n",
       "         -2.1744, -2.3370],\n",
       "        [-2.3918, -2.4286, -2.4023, -2.0753, -2.3680, -2.2472, -2.2901, -2.3122,\n",
       "         -2.2232, -2.3390],\n",
       "        [-2.3884, -2.4643, -2.4158, -2.0082, -2.3498, -2.2827, -2.3484, -2.3738,\n",
       "         -2.1804, -2.2968],\n",
       "        [-2.3740, -2.3992, -2.4114, -2.1247, -2.3529, -2.2650, -2.3341, -2.3354,\n",
       "         -2.1912, -2.2772],\n",
       "        [-2.2930, -2.4552, -2.4512, -2.1154, -2.2899, -2.2449, -2.3218, -2.3848,\n",
       "         -2.1815, -2.3421],\n",
       "        [-2.3556, -2.5127, -2.4694, -2.0139, -2.3107, -2.2590, -2.3557, -2.3944,\n",
       "         -2.1455, -2.3094],\n",
       "        [-2.3789, -2.4998, -2.4462, -2.0183, -2.3256, -2.2694, -2.2933, -2.3754,\n",
       "         -2.1799, -2.3261],\n",
       "        [-2.3371, -2.4566, -2.4613, -2.0310, -2.2825, -2.2494, -2.3623, -2.3775,\n",
       "         -2.2252, -2.3168],\n",
       "        [-2.3288, -2.4464, -2.4001, -2.0937, -2.3079, -2.2463, -2.3390, -2.4095,\n",
       "         -2.1997, -2.3060],\n",
       "        [-2.3295, -2.4659, -2.4704, -2.0716, -2.2984, -2.2808, -2.3473, -2.3853,\n",
       "         -2.1945, -2.2494],\n",
       "        [-2.4061, -2.4542, -2.4556, -2.0549, -2.3512, -2.2612, -2.2506, -2.3556,\n",
       "         -2.2046, -2.3023],\n",
       "        [-2.3905, -2.5027, -2.4727, -2.0805, -2.3102, -2.2485, -2.2693, -2.3588,\n",
       "         -2.1696, -2.2988],\n",
       "        [-2.3351, -2.5301, -2.4442, -2.0502, -2.3100, -2.2706, -2.2987, -2.3595,\n",
       "         -2.1694, -2.3388],\n",
       "        [-2.3985, -2.4750, -2.4391, -2.0474, -2.3296, -2.2463, -2.2828, -2.3691,\n",
       "         -2.1683, -2.3476],\n",
       "        [-2.3129, -2.4178, -2.3709, -2.1771, -2.3386, -2.2974, -2.2822, -2.3551,\n",
       "         -2.2288, -2.2674],\n",
       "        [-2.3654, -2.5186, -2.4550, -2.1059, -2.3548, -2.3352, -2.1972, -2.3395,\n",
       "         -2.1218, -2.3136],\n",
       "        [-2.3230, -2.4411, -2.4022, -2.1733, -2.2960, -2.3512, -2.2472, -2.3731,\n",
       "         -2.1822, -2.2726]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T08:50:51.645240Z",
     "start_time": "2020-01-25T08:50:51.582728Z"
    }
   },
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "nllloss = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T10:14:31.782761Z",
     "start_time": "2020-01-25T10:14:31.730954Z"
    }
   },
   "outputs": [],
   "source": [
    "p = softmax(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T10:14:33.617892Z",
     "start_time": "2020-01-25T10:14:33.544401Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0911, 0.0816, 0.0856, 0.1334, 0.0968, 0.1051, 0.0995, 0.0913, 0.1160,\n",
       "         0.0995],\n",
       "        [0.1011, 0.0889, 0.0906, 0.1124, 0.0984, 0.1065, 0.0971, 0.0929, 0.1103,\n",
       "         0.1017],\n",
       "        [0.0920, 0.0832, 0.0844, 0.1359, 0.0999, 0.1050, 0.0988, 0.0940, 0.1124,\n",
       "         0.0943],\n",
       "        [0.0955, 0.0894, 0.0900, 0.1236, 0.0977, 0.0990, 0.1025, 0.0932, 0.1107,\n",
       "         0.0983],\n",
       "        [0.0975, 0.0813, 0.0815, 0.1327, 0.0970, 0.1078, 0.0974, 0.0947, 0.1141,\n",
       "         0.0959],\n",
       "        [0.0946, 0.0881, 0.0842, 0.1245, 0.1027, 0.1069, 0.0968, 0.0951, 0.1134,\n",
       "         0.0939],\n",
       "        [0.0978, 0.0862, 0.0816, 0.1338, 0.1001, 0.1047, 0.0958, 0.0886, 0.1086,\n",
       "         0.1028],\n",
       "        [0.0893, 0.0841, 0.0873, 0.1197, 0.0994, 0.1048, 0.1049, 0.1016, 0.1142,\n",
       "         0.0947],\n",
       "        [0.0943, 0.0838, 0.0859, 0.1234, 0.0971, 0.1009, 0.1017, 0.0937, 0.1166,\n",
       "         0.1026],\n",
       "        [0.0965, 0.0837, 0.0876, 0.1252, 0.0960, 0.1037, 0.0999, 0.0966, 0.1149,\n",
       "         0.0960],\n",
       "        [0.0911, 0.0816, 0.0856, 0.1334, 0.0968, 0.1051, 0.0995, 0.0913, 0.1160,\n",
       "         0.0995],\n",
       "        [0.0913, 0.0859, 0.0886, 0.1277, 0.0978, 0.1088, 0.0999, 0.0924, 0.1104,\n",
       "         0.0971],\n",
       "        [0.0943, 0.0838, 0.0859, 0.1234, 0.0971, 0.1009, 0.1017, 0.0937, 0.1166,\n",
       "         0.1026],\n",
       "        [0.0975, 0.0813, 0.0815, 0.1327, 0.0970, 0.1078, 0.0974, 0.0947, 0.1141,\n",
       "         0.0959],\n",
       "        [0.0941, 0.0853, 0.0826, 0.1353, 0.0992, 0.1034, 0.0981, 0.0930, 0.1094,\n",
       "         0.0996],\n",
       "        [0.0895, 0.0814, 0.0907, 0.1264, 0.0948, 0.1027, 0.1092, 0.0935, 0.1148,\n",
       "         0.0970],\n",
       "        [0.0931, 0.0819, 0.0865, 0.1233, 0.0949, 0.1046, 0.1074, 0.0978, 0.1143,\n",
       "         0.0963],\n",
       "        [0.0911, 0.0908, 0.0920, 0.1153, 0.0954, 0.1026, 0.1044, 0.1005, 0.1112,\n",
       "         0.0966],\n",
       "        [0.0975, 0.0841, 0.0896, 0.1220, 0.0955, 0.1032, 0.1011, 0.0984, 0.1134,\n",
       "         0.0951],\n",
       "        [0.0954, 0.0847, 0.0847, 0.1281, 0.0971, 0.0997, 0.1062, 0.0934, 0.1124,\n",
       "         0.0984],\n",
       "        [0.0968, 0.0854, 0.0863, 0.1296, 0.0937, 0.1075, 0.0979, 0.0933, 0.1127,\n",
       "         0.0967],\n",
       "        [0.0968, 0.0854, 0.0863, 0.1296, 0.0937, 0.1075, 0.0979, 0.0933, 0.1127,\n",
       "         0.0967],\n",
       "        [0.0961, 0.0860, 0.0864, 0.1298, 0.0994, 0.0995, 0.1010, 0.0933, 0.1092,\n",
       "         0.0994],\n",
       "        [0.0901, 0.0813, 0.0849, 0.1277, 0.0984, 0.1035, 0.1063, 0.0938, 0.1124,\n",
       "         0.1016],\n",
       "        [0.0911, 0.0908, 0.0920, 0.1153, 0.0954, 0.1026, 0.1044, 0.1005, 0.1112,\n",
       "         0.0966],\n",
       "        [0.0983, 0.0865, 0.0880, 0.1181, 0.0944, 0.1014, 0.0995, 0.0978, 0.1125,\n",
       "         0.1033],\n",
       "        [0.0951, 0.0835, 0.0858, 0.1290, 0.0960, 0.1036, 0.1034, 0.0959, 0.1138,\n",
       "         0.0939],\n",
       "        [0.0954, 0.0838, 0.0876, 0.1313, 0.0995, 0.1041, 0.0959, 0.0949, 0.1100,\n",
       "         0.0975],\n",
       "        [0.0921, 0.0837, 0.0901, 0.1218, 0.0958, 0.1034, 0.1024, 0.0978, 0.1146,\n",
       "         0.0984],\n",
       "        [0.0963, 0.0851, 0.0858, 0.1240, 0.1032, 0.0973, 0.1002, 0.0947, 0.1163,\n",
       "         0.0970],\n",
       "        [0.1010, 0.0877, 0.0880, 0.1195, 0.0995, 0.1047, 0.1003, 0.0943, 0.1105,\n",
       "         0.0945],\n",
       "        [0.0921, 0.0837, 0.0901, 0.1218, 0.0958, 0.1034, 0.1024, 0.0978, 0.1146,\n",
       "         0.0984],\n",
       "        [0.0951, 0.0828, 0.0843, 0.1321, 0.0953, 0.1051, 0.1019, 0.0908, 0.1111,\n",
       "         0.1015],\n",
       "        [0.0953, 0.0834, 0.0873, 0.1265, 0.0945, 0.1073, 0.1003, 0.0928, 0.1130,\n",
       "         0.0997],\n",
       "        [0.0943, 0.0838, 0.0859, 0.1234, 0.0971, 0.1009, 0.1017, 0.0937, 0.1166,\n",
       "         0.1026],\n",
       "        [0.0983, 0.0858, 0.0888, 0.1236, 0.1024, 0.1055, 0.0937, 0.0884, 0.1131,\n",
       "         0.1005],\n",
       "        [0.0966, 0.0881, 0.0902, 0.1223, 0.0995, 0.1066, 0.0962, 0.0901, 0.1105,\n",
       "         0.0998],\n",
       "        [0.0934, 0.0800, 0.0881, 0.1281, 0.0957, 0.0996, 0.1001, 0.0937, 0.1158,\n",
       "         0.1054],\n",
       "        [0.0977, 0.0862, 0.0900, 0.1157, 0.0948, 0.1028, 0.1023, 0.0992, 0.1109,\n",
       "         0.1003],\n",
       "        [0.0958, 0.0824, 0.0910, 0.1164, 0.1011, 0.0974, 0.1054, 0.0966, 0.1142,\n",
       "         0.0997],\n",
       "        [0.0968, 0.0833, 0.0835, 0.1239, 0.0985, 0.0995, 0.1045, 0.0933, 0.1128,\n",
       "         0.1040],\n",
       "        [0.0941, 0.0844, 0.0890, 0.1199, 0.0988, 0.1008, 0.1031, 0.0996, 0.1137,\n",
       "         0.0966],\n",
       "        [0.0915, 0.0882, 0.0905, 0.1255, 0.0937, 0.1057, 0.1013, 0.0990, 0.1083,\n",
       "         0.0964],\n",
       "        [0.0918, 0.0851, 0.0893, 0.1342, 0.0954, 0.1020, 0.0955, 0.0931, 0.1130,\n",
       "         0.1006],\n",
       "        [0.0931, 0.0908, 0.0897, 0.1195, 0.0951, 0.1038, 0.0969, 0.0968, 0.1118,\n",
       "         0.1026],\n",
       "        [0.1010, 0.0858, 0.0862, 0.1206, 0.1013, 0.1059, 0.0981, 0.0921, 0.1129,\n",
       "         0.0961],\n",
       "        [0.0948, 0.0810, 0.0846, 0.1335, 0.0992, 0.1045, 0.0948, 0.0912, 0.1170,\n",
       "         0.0993],\n",
       "        [0.0927, 0.0821, 0.0866, 0.1329, 0.0977, 0.1034, 0.1009, 0.0930, 0.1131,\n",
       "         0.0977],\n",
       "        [0.0966, 0.0857, 0.0853, 0.1312, 0.1020, 0.1055, 0.0942, 0.0928, 0.1080,\n",
       "         0.0986],\n",
       "        [0.0974, 0.0866, 0.0907, 0.1232, 0.0995, 0.1058, 0.0964, 0.0899, 0.1108,\n",
       "         0.0997],\n",
       "        [0.0973, 0.0849, 0.0846, 0.1260, 0.1004, 0.1022, 0.0956, 0.0921, 0.1114,\n",
       "         0.1055],\n",
       "        [0.0902, 0.0859, 0.0858, 0.1281, 0.0953, 0.1042, 0.1053, 0.0948, 0.1103,\n",
       "         0.1000],\n",
       "        [0.0916, 0.0819, 0.0844, 0.1249, 0.0992, 0.1056, 0.1034, 0.0945, 0.1142,\n",
       "         0.1004],\n",
       "        [0.0968, 0.0797, 0.0868, 0.1287, 0.0993, 0.1032, 0.1004, 0.0945, 0.1142,\n",
       "         0.0964],\n",
       "        [0.0909, 0.0842, 0.0872, 0.1291, 0.0973, 0.1058, 0.1020, 0.0936, 0.1144,\n",
       "         0.0956],\n",
       "        [0.0990, 0.0891, 0.0934, 0.1134, 0.0965, 0.1005, 0.1021, 0.0949, 0.1077,\n",
       "         0.1036],\n",
       "        [0.0939, 0.0806, 0.0859, 0.1217, 0.0949, 0.0968, 0.1111, 0.0964, 0.1198,\n",
       "         0.0989],\n",
       "        [0.0980, 0.0871, 0.0905, 0.1138, 0.1007, 0.0953, 0.1057, 0.0932, 0.1128,\n",
       "         0.1030]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T00:22:57.356888Z",
     "start_time": "2020-01-24T00:22:57.307719Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function flash.core.data_utils.TrainDataServer.__init__.<locals>.<lambda>()>,\n",
       "            {'outputs': {'up': {'y': tensor([[-3.0331, -1.2355, -2.3531, -2.3925, -2.4973, -3.2562, -2.7663, -2.3941,\n",
       "                        -2.0924, -2.5733],\n",
       "                       [-3.4033, -2.6814, -2.1397, -1.6921, -2.9154, -1.9642, -2.8226, -1.9775,\n",
       "                        -2.5565, -2.0670],\n",
       "                       [-2.9693, -1.6624, -2.9843, -2.0127, -2.8591, -2.9935, -2.0942, -2.7243,\n",
       "                        -1.6810, -2.3818],\n",
       "                       [-2.4177, -2.9134, -2.3364, -1.6145, -2.5476, -2.5784, -2.1098, -2.2998,\n",
       "                        -2.3147, -2.4487],\n",
       "                       [-2.5840, -2.0995, -2.4297, -2.2582, -2.2021, -2.6670, -2.1887, -2.4873,\n",
       "                        -2.1505, -2.1392],\n",
       "                       [-2.6444, -2.4692, -2.6925, -1.8929, -2.8744, -2.1172, -1.9657, -2.4038,\n",
       "                        -2.2271, -2.1995],\n",
       "                       [-3.1309, -1.9826, -1.7994, -1.9629, -2.7011, -2.2170, -2.1921, -2.7254,\n",
       "                        -2.5148, -2.5433],\n",
       "                       [-2.3479, -3.6660, -2.8482, -2.1767, -2.8751, -2.7117, -1.2037, -3.7583,\n",
       "                        -2.0559, -2.0154],\n",
       "                       [-4.1781, -3.7153, -3.1214, -0.5307, -3.4077, -2.5020, -3.5080, -2.4669,\n",
       "                        -2.9826, -3.0467],\n",
       "                       [-3.3038, -2.6041, -2.6663, -1.5484, -2.3914, -2.4612, -2.3602, -1.7322,\n",
       "                        -2.5764, -2.4888],\n",
       "                       [-3.0519, -2.9896, -2.5727, -0.7928, -3.2670, -2.6967, -2.9210, -2.2825,\n",
       "                        -2.9938, -2.7814],\n",
       "                       [-3.1333, -3.3001, -2.1227, -1.2776, -3.4520, -2.9627, -2.9605, -1.6902,\n",
       "                        -3.6568, -1.7391]])}}, 'loss': {'up': tensor(1.7355)}})"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds1.current_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T14:51:03.008887Z",
     "start_time": "2020-01-23T14:51:02.936675Z"
    }
   },
   "outputs": [],
   "source": [
    "class Temp():\n",
    "    def __init__(self, l):\n",
    "        self.list = l\n",
    "        \n",
    "    def __iter__(self):\n",
    "        print(\"iter\")\n",
    "        self._l = iter(self.list)\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        return next(self._l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T14:51:03.113191Z",
     "start_time": "2020-01-23T14:51:03.097342Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp = Temp([1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T14:51:03.306846Z",
     "start_time": "2020-01-23T14:51:03.271594Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for i in tmp:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T14:51:04.352525Z",
     "start_time": "2020-01-23T14:51:04.270569Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for i in tmp:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T14:25:23.951038Z",
     "start_time": "2020-01-23T14:25:23.909446Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'outputs/ev/y': tensor([[-2.4509, -2.3101, -2.3044, -1.8983, -2.6456, -2.3190, -2.4541, -2.1979,\n",
       "          -2.4048, -2.2229],\n",
       "         [-2.4792, -2.2891, -2.2637, -1.9546, -2.6114, -2.2988, -2.4784, -2.1929,\n",
       "          -2.3427, -2.2645],\n",
       "         [-2.4481, -2.2974, -2.3388, -1.9652, -2.5741, -2.3655, -2.4591, -2.1345,\n",
       "          -2.3696, -2.2164],\n",
       "         [-2.5014, -2.3376, -2.3617, -1.8615, -2.5707, -2.3960, -2.4191, -2.2114,\n",
       "          -2.3710, -2.1870],\n",
       "         [-2.4859, -2.2364, -2.2402, -2.0082, -2.3785, -2.3877, -2.3664, -2.2785,\n",
       "          -2.4692, -2.2652],\n",
       "         [-2.3668, -2.3091, -2.2742, -1.9547, -2.4272, -2.4129, -2.3876, -2.3449,\n",
       "          -2.4199, -2.2265],\n",
       "         [-2.4660, -2.2338, -2.2527, -1.9562, -2.4804, -2.4166, -2.3631, -2.2506,\n",
       "          -2.3944, -2.3246]])}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds2 = tm.data_server_set['evaluate']\n",
    "ds2.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T14:25:49.657805Z",
     "start_time": "2020-01-23T14:25:49.571872Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'val'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds2.current_data_loader_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T14:18:02.775969Z",
     "start_time": "2020-01-23T14:18:02.711050Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function flash.core.data_utils.TrainDataServer.__init__.<locals>.<lambda>()>,\n",
       "            {'outputs': {'model': {'y': tensor([[-1.9741, -2.2178, -2.4961, -2.2982, -2.4555, -2.2134, -2.4460, -2.5294,\n",
       "                        -2.2897, -2.2383],\n",
       "                       [-2.4829, -2.1912, -2.3693, -2.0773, -2.3470, -2.6201, -2.3363, -2.2773,\n",
       "                        -2.1844, -2.2476],\n",
       "                       [-2.2419, -2.2760, -2.3020, -2.3078, -2.1298, -2.2984, -2.3899, -2.4092,\n",
       "                        -2.4792, -2.2360],\n",
       "                       [-2.3620, -2.3347, -2.2606, -1.9512, -2.4382, -2.2875, -2.2999, -2.2435,\n",
       "                        -2.7872, -2.2465],\n",
       "                       [-2.2266, -2.0384, -2.2657, -2.2339, -2.4156, -2.4095, -2.2907, -2.4704,\n",
       "                        -2.4852, -2.2752],\n",
       "                       [-2.2922, -2.3219, -2.4574, -2.2366, -2.4117, -2.5749, -2.1518, -1.9447,\n",
       "                        -2.4090, -2.3713],\n",
       "                       [-2.1283, -2.1718, -2.3789, -2.3344, -2.6563, -2.3724, -2.3028, -2.0964,\n",
       "                        -2.3689, -2.3276],\n",
       "                       [-2.3924, -2.0969, -2.2282, -2.3271, -2.2006, -2.5921, -2.3197, -2.2469,\n",
       "                        -2.2545, -2.4546],\n",
       "                       [-2.3172, -2.1259, -2.4443, -2.2723, -2.4528, -2.2904, -2.4076, -2.1174,\n",
       "                        -2.1306, -2.5792],\n",
       "                       [-2.4107, -2.2619, -2.1600, -2.1066, -2.4496, -2.2663, -2.4892, -2.2068,\n",
       "                        -2.4188, -2.3327],\n",
       "                       [-2.3849, -2.1317, -2.0291, -2.2746, -2.5080, -2.4853, -2.4575, -2.4022,\n",
       "                        -2.0619, -2.4436],\n",
       "                       [-2.3045, -1.9988, -2.3966, -2.3839, -2.4913, -2.3460, -2.3593, -2.1667,\n",
       "                        -2.3267, -2.3407]])}},\n",
       "             'loss': {'model': tensor(2.2934)}})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.current_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T14:18:04.566275Z",
     "start_time": "2020-01-23T14:18:04.511547Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function flash.core.data_utils.TrainDataServer.__init__.<locals>.<lambda>()>,\n",
       "            {'outputs': {'model': {'y': tensor([[-2.2850, -2.2918, -2.2173, -2.1412, -2.5096, -2.4006, -2.4183, -2.2720,\n",
       "                        -2.3378, -2.2070],\n",
       "                       [-2.3001, -2.2240, -2.2181, -2.2016, -2.4948, -2.3798, -2.4446, -2.2887,\n",
       "                        -2.2776, -2.2408],\n",
       "                       [-2.2259, -2.2514, -2.2707, -2.2234, -2.4646, -2.4029, -2.3824, -2.2798,\n",
       "                        -2.3384, -2.2194],\n",
       "                       [-2.2863, -2.2375, -2.2621, -2.1776, -2.4440, -2.4381, -2.3589, -2.3477,\n",
       "                        -2.2791, -2.2298],\n",
       "                       [-2.3760, -2.1657, -2.2414, -2.1750, -2.3041, -2.3731, -2.3718, -2.3781,\n",
       "                        -2.3954, -2.2802],\n",
       "                       [-2.2139, -2.2473, -2.2627, -2.1829, -2.3155, -2.4565, -2.3906, -2.3607,\n",
       "                        -2.3766, -2.2537],\n",
       "                       [-2.3297, -2.1529, -2.2514, -2.1385, -2.3856, -2.4168, -2.3862, -2.3155,\n",
       "                        -2.3263, -2.3660]])}}})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds2.current_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T14:10:22.778374Z",
     "start_time": "2020-01-23T14:10:22.721620Z"
    }
   },
   "outputs": [],
   "source": [
    "ds2.data_warehouse.data_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T14:18:46.824658Z",
     "start_time": "2020-01-23T14:18:46.789881Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('process-1',\n",
       "              (<flash.core.process.ModelFlowProcess at 0x7f7ee3001978>, {}))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm.evaluate_process_manager.process_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-22T16:51:24.261998Z",
     "start_time": "2020-01-22T16:51:24.228775Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp = tm.update_process_manager.process_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-22T16:57:17.974915Z",
     "start_time": "2020-01-22T16:57:17.893604Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-345fbd91c849>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MachineLearning/DL/pytorch/pytorch-flash/flash/core/data_utils.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "for i in ds:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-22T16:51:52.522485Z",
     "start_time": "2020-01-22T16:51:52.418143Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TrainDataServer' object has no attribute 'inputs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-da67085f879a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'process-1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/MachineLearning/DL/pytorch/pytorch-flash/flash/core/process.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, state, process_config)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;31m# move iter_ into state ???\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;31m# maybe should not do because iter_ is not referred outside loop ...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mBreak_iteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocess_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mBreak_iteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MachineLearning/DL/pytorch/pytorch-flash/flash/core/process.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, iter_, state, process_config)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mKeep_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs_type_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeep_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mKeep_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeep_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_portion\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_server\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m             \u001b[0;31m# add data_controller ? (inputsをdata_serverに要求)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;31m# modelはforward_wrap済み、と仮定\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MachineLearning/DL/pytorch/pytorch-flash/flash/core/data_utils.py\u001b[0m in \u001b[0;36mgenerate_inputs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;31m#self._reset_inner_iter()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_gateway\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TrainDataServer' object has no attribute 'inputs'"
     ]
    }
   ],
   "source": [
    "tmp['process-1'][0].run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-22T16:47:03.231672Z",
     "start_time": "2020-01-22T16:47:03.168773Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = tm.data_server_set['update']\n",
    "\n",
    "ds.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-22T16:36:12.500516Z",
     "start_time": "2020-01-22T16:36:12.437905Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = tm.data_server_set['update']\n",
    "\n",
    "ds.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-22T16:33:06.641004Z",
     "start_time": "2020-01-22T16:33:06.590637Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasattr(update_process, 'name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-22T16:32:29.551433Z",
     "start_time": "2020-01-22T16:32:29.490961Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ModelFlowProcess' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-a70f7a5b1a65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mupdate_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'ModelFlowProcess' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "update_process.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T14:20:39.873148Z",
     "start_time": "2020-01-23T14:20:39.854613Z"
    }
   },
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Temp():\n",
    "    def add_process(self):\n",
    "        pass\n",
    "    \n",
    "    def reset_update_info(self):\n",
    "        config = self.config\n",
    "        config['trainer']['update_process_list'] = []\n",
    "\n",
    "    def reset_evaluate_info(self):\n",
    "        config = self.config\n",
    "        config['trainer']['evaluate_process_list'] = []\n",
    "\n",
    "    def add_update_info(self, **update_info):\n",
    "        assert 'model' in update_info\n",
    "        #assert 'loss_fn' in update_info\n",
    "        assert all(map(lambda x:isinstance(x, str) or isinstance(x, int) or isinstance(x, float), update_info.values()))\n",
    "        config = self.config\n",
    "        update_process_list = config['trainer']['update_process_list']\n",
    "        update_process_list.append(update_info)\n",
    "        \n",
    "    def add_evaluate_info(self, **evaluate_info):\n",
    "        assert 'model' in evaluate_info\n",
    "        assert all(map(lambda x:isinstance(x, str), evaluate_info.values()))\n",
    "        config = self.config\n",
    "        evaluate_process_list = config['trainer']['evaluate_process_list']\n",
    "        evaluate_process_list.append(evaluate_info)\n",
    "\n",
    "\n",
    "    def set_objects(self):\n",
    "        import copy\n",
    "        config = self.config\n",
    "        trainer = config['trainer']\n",
    "        objects = config['objects']\n",
    "        key2obj = {\n",
    "            'model' : objects['models'],\n",
    "            'loss_fn' : objects['loss_fns'],\n",
    "            'optimizer' : objects['optimizers'],\n",
    "            'skip_condition' : objects['skip_condition'],\n",
    "            'break_condition' : objects['break_condition'],\n",
    "            'pre_operator' : objects['pre_operator'],\n",
    "            'post_operator' : objects['post_operator'],\n",
    "        }\n",
    "\n",
    "        update_process_list = []\n",
    "        for update_info in trainer['update_process_list']:\n",
    "            update_info_ = copy.copy(update_info)\n",
    "            for key, obj in key2obj.items():\n",
    "                if key in update_info:\n",
    "                    assert update_info[key] in obj.keys(), f\"'{key}' key '{update_info[key]}' is not registered\"\n",
    "                    update_info_[key] = obj[update_info[key]]\n",
    "            update_process_list.append(update_info_)\n",
    "        objects.update({'update_process_list' : update_process_list})\n",
    "\n",
    "        key2obj = {\n",
    "            'model' : objects['models'],\n",
    "            'skip_condition' : objects['skip_condition'],\n",
    "            'pre_operator' : objects['pre_operator'],\n",
    "            'post_operator' : objects['post_operator'],\n",
    "        }\n",
    "\n",
    "        evaluate_process_list = []\n",
    "        for evaluate_info in trainer['evaluate_process_list']:\n",
    "            evaluate_info_ = copy.copy(evaluate_info)\n",
    "            for key, obj in key2obj.items():\n",
    "                if key in evaluate_info:\n",
    "                    assert evaluate_info[key] in obj.keys(), f\"'{key}' key '{evaluate_info[key]}' is not registered\"\n",
    "                    evaluate_info_[key] = obj[evaluate_info[key]]\n",
    "            evaluate_process_list.append(evaluate_info_)\n",
    "        objects.update({'evaluate_process_list' : evaluate_process_list})\n",
    "\n",
    "\n",
    "    def setup_engines(self, trainer_args={}, evaluator_args={}):\n",
    "        #from flash.engine import create_trainer, create_evaluator\n",
    "        from develop.flash.engine import create_trainer, create_evaluator\n",
    "        config = self.config\n",
    "        batch_size = config['train']['batch_size']###\n",
    "        #eval_batch_size = config['others']['eval_batch_size']###\n",
    "        objects = config['objects']\n",
    "        device = config['device']['name']\n",
    "        grad_accumulation_steps = config['others'].get('grad_accumulation_steps', 1)\n",
    "        metrics = objects['metrics']\n",
    "        #train_loader = objects['data']['train_loader']\n",
    "        update_process_list = objects['update_process_list']\n",
    "        #update_info_list = objects['update_info_list']\n",
    "        evaluate_process_list = objects['evaluate_process_list']\n",
    "        #evaluate_info_list = objects['evaluate_info_list']\n",
    "\n",
    "        trainer = create_trainer(process_list=update_process_list, batch_size=batch_size, **trainer_args)\n",
    "        train_evaluator = create_evaluator(process_list=evaluate_process_list, metrics=metrics, **evaluator_args)\n",
    "        evaluator_args.update({ 'data_server' : train_evaluator.data_server })# temporal\n",
    "        val_evaluator = create_evaluator(process_list=evaluate_process_list, metrics=metrics, **evaluator_args)\n",
    "\n",
    "        objects['engine'] = {\n",
    "            'trainer' : trainer,\n",
    "            'train_evaluator' : train_evaluator,\n",
    "            'val_evaluator' : val_evaluator\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T13:13:39.225721Z",
     "start_time": "2020-01-18T13:13:39.163913Z"
    }
   },
   "source": [
    "em = EventManager(data_server=ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T13:13:40.375558Z",
     "start_time": "2020-01-18T13:13:40.320913Z"
    }
   },
   "source": [
    "pm = ProcessManager(data_server=ds, event_manager=em)\n",
    "pm.register_process(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T13:14:22.959614Z",
     "start_time": "2020-01-18T13:14:22.934139Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2786, -0.1996, -0.0905],\n",
       "         [ 0.1691,  0.1847, -0.1437],\n",
       "         [-0.3222, -0.2673,  0.1372]]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv1.weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T13:14:26.223623Z",
     "start_time": "2020-01-18T13:14:25.939934Z"
    }
   },
   "outputs": [],
   "source": [
    "pm.run(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T13:14:29.974810Z",
     "start_time": "2020-01-18T13:14:29.907649Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2788, -0.1997, -0.0905],\n",
       "         [ 0.1692,  0.1847, -0.1435],\n",
       "         [-0.3222, -0.2678,  0.1369]]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv1.weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-19T07:24:12.417168Z",
     "start_time": "2020-01-19T07:24:12.360994Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global/epoch': 3,\n",
       " 'global/iteration': 41,\n",
       " 'run/epoch': 0,\n",
       " 'run/iteration': 20}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# old version\n",
    "\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "from ignite.metrics import Accuracy\n",
    "\n",
    "from flash.utils import wrap_metrics, get_y_values\n",
    "from flash.metrics import Loss\n",
    "from flash.files import prepare_target_dir\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    ToDo\n",
    "    * assign a device to each model model\n",
    "    * add the following properties\n",
    "        * __repr__\n",
    "        * __str__\n",
    "        * __dict__\n",
    "        * __getter__\n",
    "        * __setter__\n",
    "        * quick access to the field in config\n",
    "            + manager.config.objects.engine.trainer, for example\n",
    "\"\"\"\n",
    "class TrainManager():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    \"\"\"experimental\"\"\"\n",
    "    def load_config(self, config_path):\n",
    "        ext = os.path.splitext(config_path)[1]\n",
    "        if ext == \".json\":\n",
    "            import json\n",
    "            with open(config_path, \"r\") as f:\n",
    "                config = json.load(f)\n",
    "        elif ext == \".toml\":\n",
    "            import toml\n",
    "            with open(config_path, \"r\") as f:\n",
    "                config = toml.load(f)\n",
    "        elif ext == \".yaml\" or ext == \".yml\":\n",
    "            import yaml\n",
    "            with open(config_path, \"r\") as f:\n",
    "                config = yaml.safe_load(f)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        self.set_config(config)\n",
    "\n",
    "    \"\"\"experimental\"\"\"\n",
    "    def set_seed(self, seed_dict={}):\n",
    "        if seed_dict is not None:\n",
    "            import random\n",
    "            import numpy as np\n",
    "            import torch\n",
    "            radom.seed(seed_dict.get(\"random\", 0))\n",
    "            np.radom.seed(seed_dict.get(\"numpy\", 0))\n",
    "            torch.manual_seed(seed_dict.get(\"torch\", 0))\n",
    "\n",
    "    def set_config(self, config: dict):\n",
    "        self.config = config\n",
    "        self.check()\n",
    "\n",
    "    def add_model_from_generator(self, model_name:str, model_generator, model_args={}, device=None):\n",
    "        assert isinstance(model_name ,str)\n",
    "        config = self.config\n",
    "        model = model_generator(**model_args)\n",
    "        device = config['device']['name'] if device is None else device\n",
    "        if device == 'cuda':\n",
    "            model.cuda(config['device']['gpu'])\n",
    "        config['objects']['models'].update({model_name : model})\n",
    "        \n",
    "        \"\"\"\n",
    "        if config['device']['num_gpu'] > 0:\n",
    "            device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "            #if device == 'cuda':\n",
    "            #    model.cuda(config['device']['gpu'])\n",
    "            config['device']['name'] = device\n",
    "        else:\n",
    "            config['device']['name'] = 'cpu'\n",
    "        \n",
    "        config['objects']['model'] = model\n",
    "        \"\"\"\n",
    "\n",
    "    def add_model(self, model_name:str, model, device=None):\n",
    "        assert isinstance(model_name ,str)\n",
    "        config = self.config\n",
    "        # temporal\n",
    "        if device is None:\n",
    "            device_cfg = self.config['device']\n",
    "            num_gpu = device_cfg.get('num_gpu', 1)\n",
    "            if num_gpu > 0:\n",
    "                device = device_cfg.get('gpu', 0)\n",
    "            else:\n",
    "                device = -1\n",
    "        config['objects']['models'].update({model_name : model.cuda(device) if torch.cuda.is_available() or device >= 0 else model})\n",
    "\n",
    "    def add_object(self, obj_key:str, obj_name:str, obj):\n",
    "        assert isinstance(obj_key ,str)\n",
    "        assert isinstance(obj_name ,str)\n",
    "        config = self.config\n",
    "        config['objects'][obj_key].update({obj_name : obj})\n",
    "\n",
    "    def add_optimizer(self, optimizer_name:str, optimizer):\n",
    "        assert isinstance(optimizer_name ,str)\n",
    "        config = self.config\n",
    "        config['objects']['optimizers'].update({optimizer_name : optimizer})\n",
    "\n",
    "    # keep\n",
    "    def add_loss_fn_old(self, loss_fn_name, loss_fn, output_transform=get_y_values):\n",
    "        assert isinstance(loss_fn_name ,str)\n",
    "        config = self.config\n",
    "        loss_fn_ = wrap_metrics(loss_fn, output_transform)\n",
    "        config['objects']['loss_fns'].update({loss_fn_name : loss_fn_})\n",
    "\n",
    "    def add_loss_fn(self, loss_fn_name, loss_fn):\n",
    "        assert isinstance(loss_fn_name ,str)\n",
    "        config = self.config\n",
    "        config['objects']['loss_fns'].update({loss_fn_name : loss_fn})\n",
    "\n",
    "    def add_skip_condition(self, skip_condition_name, skip_condition):\n",
    "        assert isinstance(skip_condition_name ,str)\n",
    "        config = self.config\n",
    "        config['objects']['skip_condition'].update({skip_condition_name : skip_condition})\n",
    "\n",
    "    def add_break_condition(self, break_condition_name, break_condition):\n",
    "        assert isinstance(break_condition_name ,str)\n",
    "        config = self.config\n",
    "        config['objects']['break_condition'].update({break_condition_name : break_condition})\n",
    "\n",
    "    def add_pre_operator(self, pre_operator_name, pre_operator):\n",
    "        assert isinstance(pre_operator_name ,str)\n",
    "        config = self.config\n",
    "        config['objects']['pre_operator'].update({pre_operator_name : pre_operator})\n",
    "\n",
    "    def add_post_operator(self, post_operator_name, post_operator):\n",
    "        assert isinstance(post_operator_name ,str)\n",
    "        config = self.config\n",
    "        config['objects']['post_operator'].update({post_operator_name : post_operator})\n",
    "\n",
    "    def reset_update_info(self):\n",
    "        config = self.config\n",
    "        config['trainer']['update_process_list'] = []\n",
    "\n",
    "    def reset_evaluate_info(self):\n",
    "        config = self.config\n",
    "        config['trainer']['evaluate_process_list'] = []\n",
    "\n",
    "    def add_update_info(self, **update_info):\n",
    "        assert 'model' in update_info\n",
    "        #assert 'loss_fn' in update_info\n",
    "        assert all(map(lambda x:isinstance(x, str) or isinstance(x, int) or isinstance(x, float), update_info.values()))\n",
    "        config = self.config\n",
    "        update_process_list = config['trainer']['update_process_list']\n",
    "        update_process_list.append(update_info)\n",
    "        \n",
    "    def add_evaluate_info(self, **evaluate_info):\n",
    "        assert 'model' in evaluate_info\n",
    "        assert all(map(lambda x:isinstance(x, str), evaluate_info.values()))\n",
    "        config = self.config\n",
    "        evaluate_process_list = config['trainer']['evaluate_process_list']\n",
    "        evaluate_process_list.append(evaluate_info)\n",
    "\n",
    "    def add_process(self, process, mode='update'):\n",
    "        if isinstance(process, list):\n",
    "            raise NotImplementedError\n",
    "        elif isinstance(process, dict):\n",
    "            raise NotImplementedError\n",
    "        else:\n",
    "            process_list = [process]\n",
    "            # diagnosis_process(process)\n",
    "        \n",
    "        config = self.config\n",
    "        if mode == 'update':\n",
    "            update_process_list = config['objects']['update_process_list']\n",
    "            update_process_list.extend(process_list)\n",
    "        elif mode == 'evaluate':\n",
    "            evaluate_process_list = config['objects']['evaluate_process_list']\n",
    "            evaluate_process_list.extend(process_list)\n",
    "\n",
    "    def set_dataloader(self, train_loader, val_loader, eval_train_loader=None):\n",
    "        config = self.config\n",
    "        data = {\n",
    "            'train_loader' : train_loader,\n",
    "            'val_loader' : val_loader\n",
    "        }\n",
    "        if eval_train_loader is not None:\n",
    "            data.update({'eval_train_loader' : eval_train_loader})\n",
    "        config[\"objects\"].update({ 'data' : data })\n",
    "\n",
    "\n",
    "    # temporal ?\n",
    "    def setup_metrics(self, target_metrics, loss_fn=None, output_transform=get_y_values, target_loss_fn_names=None):\n",
    "        \"\"\"\n",
    "            ToDo\n",
    "                * Add other metrics ...\n",
    "                * Refactoring and make/unify the logic clear\n",
    "        \"\"\"\n",
    "        from flash.metrics import get_precision, get_recall, get_F1score\n",
    "        config = self.config\n",
    "        #loss_fns = self.config['objects']['loss_fns']\n",
    "\n",
    "        metrics = {}\n",
    "        if 'loss' in target_metrics:\n",
    "            if target_loss_fn_names is None:\n",
    "                #if len(loss_fns) == 1:\n",
    "                if loss_fn is not None:\n",
    "                    #loss_fn = list(loss_fns.values())[0]\n",
    "                    metrics.update({ 'loss' : Loss(loss_fn) })###\n",
    "                #else:\n",
    "                #    target_loss_fn_names = list(loss_fns.keys())\n",
    "            #if target_loss_fn_names is not None:\n",
    "            #    for name, loss_fn in loss_fns.items():\n",
    "            #        metrics.update({ f\"{name}-loss\" : Loss(loss_fn) })###\n",
    "        if 'accuracy' in target_metrics:\n",
    "            metrics.update({ 'accuracy' : Accuracy(output_transform=output_transform) })\n",
    "        Is_average = 'precision' in target_metrics\n",
    "        Is_classwise = 'precision_class' in target_metrics\n",
    "        if Is_average or Is_classwise:\n",
    "            metrics.update(get_precision(Is_average=Is_average, Is_classwise=Is_classwise, output_transform=output_transform))\n",
    "        Is_average = 'recall' in target_metrics\n",
    "        Is_classwise = 'recall_class' in target_metrics\n",
    "        if Is_average or Is_classwise:\n",
    "            metrics.update(get_recall(Is_average=Is_average, Is_classwise=Is_classwise, output_transform=output_transform))\n",
    "        Is_average = 'F1' in target_metrics\n",
    "        Is_classwise = 'F1_class' in target_metrics\n",
    "        if Is_average or Is_classwise:\n",
    "            metrics.update(get_F1score(Is_average=Is_average, Is_classwise=Is_classwise, output_transform=output_transform))\n",
    "\n",
    "        print(f\"set {tuple(list(metrics.keys()))}\")\n",
    "\n",
    "        config['objects']['metrics'] = metrics\n",
    "\n",
    "\n",
    "    # to rename the function later\n",
    "    def check(self):\n",
    "        config = self.config\n",
    "\n",
    "        config['train']['train_batch_size'] = config['train']['batch_size']###\n",
    "\n",
    "        ### change ? (temporal)\n",
    "        if config['device']['num_gpu'] > 0:\n",
    "            device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "            #if device == 'cuda':\n",
    "            #    model.cuda(config['device']['gpu'])\n",
    "            config['device']['name'] = device\n",
    "        else:\n",
    "            config['device']['name'] = 'cpu'\n",
    "\n",
    "        if 'objects' not in config.keys():\n",
    "            config['objects'] = {}\n",
    "        if 'trainer' not in config.keys():\n",
    "            config['trainer'] = {}\n",
    "            \n",
    "        for objects_key in ['models', 'loss_fns', 'optimizers', 'skip_condition', 'break_condition', 'pre_operator', 'post_operator']:\n",
    "            config['objects'].update({objects_key : {}})\n",
    "        config['objects'].update({'metrics_log' : defaultdict(lambda :[])})\n",
    "        #config['trainer'].update({'update_process_list' : []})\n",
    "        #config['trainer'].update({'evaluate_process_list' : []})\n",
    "        config['objects']['update_process_list'] = []\n",
    "        config['objects']['evaluate_process_list'] = []\n",
    "\n",
    "        self._save_dir()\n",
    "\n",
    "    def _save_dir(self):\n",
    "        \"\"\"\n",
    "            ToDo\n",
    "                * refactoring\n",
    "                * allow manager to set assert_on switching\n",
    "        \"\"\"\n",
    "        config = self.config\n",
    "        save_dir = config.get('handlers', {}).get('checkpoint', {}).get('save_dir', None)\n",
    "        if save_dir is not None:\n",
    "            prepare_target_dir(save_dir)\n",
    "        save_dir = config.get('handlers', {}).get('output', {}).get('save_dir', None)\n",
    "        if save_dir is not None:\n",
    "            prepare_target_dir(save_dir)\n",
    "        save_dir = config.get('others', {}).get('save_dir', None)\n",
    "        if save_dir is not None:\n",
    "            prepare_target_dir(save_dir)\n",
    "\n",
    "    def set_objects(self):\n",
    "        import copy\n",
    "        config = self.config\n",
    "        trainer = config['trainer']\n",
    "        objects = config['objects']\n",
    "        key2obj = {\n",
    "            'model' : objects['models'],\n",
    "            'loss_fn' : objects['loss_fns'],\n",
    "            'optimizer' : objects['optimizers'],\n",
    "            'skip_condition' : objects['skip_condition'],\n",
    "            'break_condition' : objects['break_condition'],\n",
    "            'pre_operator' : objects['pre_operator'],\n",
    "            'post_operator' : objects['post_operator'],\n",
    "        }\n",
    "\n",
    "        update_process_list = []\n",
    "        for update_info in trainer['update_process_list']:\n",
    "            update_info_ = copy.copy(update_info)\n",
    "            for key, obj in key2obj.items():\n",
    "                if key in update_info:\n",
    "                    assert update_info[key] in obj.keys(), f\"'{key}' key '{update_info[key]}' is not registered\"\n",
    "                    update_info_[key] = obj[update_info[key]]\n",
    "            update_process_list.append(update_info_)\n",
    "        objects.update({'update_process_list' : update_process_list})\n",
    "\n",
    "        key2obj = {\n",
    "            'model' : objects['models'],\n",
    "            'skip_condition' : objects['skip_condition'],\n",
    "            'pre_operator' : objects['pre_operator'],\n",
    "            'post_operator' : objects['post_operator'],\n",
    "        }\n",
    "\n",
    "        evaluate_process_list = []\n",
    "        for evaluate_info in trainer['evaluate_process_list']:\n",
    "            evaluate_info_ = copy.copy(evaluate_info)\n",
    "            for key, obj in key2obj.items():\n",
    "                if key in evaluate_info:\n",
    "                    assert evaluate_info[key] in obj.keys(), f\"'{key}' key '{evaluate_info[key]}' is not registered\"\n",
    "                    evaluate_info_[key] = obj[evaluate_info[key]]\n",
    "            evaluate_process_list.append(evaluate_info_)\n",
    "        objects.update({'evaluate_process_list' : evaluate_process_list})\n",
    "\n",
    "\n",
    "    def setup_engines(self, trainer_args={}, evaluator_args={}):\n",
    "        #from flash.engine import create_trainer, create_evaluator\n",
    "        from develop.flash.engine import create_trainer, create_evaluator\n",
    "        config = self.config\n",
    "        batch_size = config['train']['batch_size']###\n",
    "        #eval_batch_size = config['others']['eval_batch_size']###\n",
    "        objects = config['objects']\n",
    "        device = config['device']['name']\n",
    "        grad_accumulation_steps = config['others'].get('grad_accumulation_steps', 1)\n",
    "        metrics = objects['metrics']\n",
    "        #train_loader = objects['data']['train_loader']\n",
    "        update_process_list = objects['update_process_list']\n",
    "        #update_info_list = objects['update_info_list']\n",
    "        evaluate_process_list = objects['evaluate_process_list']\n",
    "        #evaluate_info_list = objects['evaluate_info_list']\n",
    "\n",
    "        trainer = create_trainer(process_list=update_process_list, batch_size=batch_size, **trainer_args)\n",
    "        train_evaluator = create_evaluator(process_list=evaluate_process_list, metrics=metrics, **evaluator_args)\n",
    "        evaluator_args.update({ 'data_server' : train_evaluator.data_server })# temporal\n",
    "        val_evaluator = create_evaluator(process_list=evaluate_process_list, metrics=metrics, **evaluator_args)\n",
    "\n",
    "        objects['engine'] = {\n",
    "            'trainer' : trainer,\n",
    "            'train_evaluator' : train_evaluator,\n",
    "            'val_evaluator' : val_evaluator\n",
    "        }\n",
    "\n",
    "\n",
    "    def create_default_events(self):\n",
    "        from flash.event import create_default_events\n",
    "        create_default_events(self.config)\n",
    "\n",
    "    def run(self):\n",
    "        config = self.config\n",
    "        seed = self.config.get('seed', {})\n",
    "        objects = config['objects']\n",
    "        trainer = objects['engine']['trainer']\n",
    "        train_loader = objects['data']['train_loader']\n",
    "        epochs = config['train']['epochs']\n",
    "\n",
    "        self.set_seed(seed.get('run', {}))\n",
    "        trainer.run(data=train_loader, max_epochs=epochs)\n",
    "        self.save_metrics()\n",
    "\n",
    "    def save_metrics(self):\n",
    "        import json\n",
    "        import os\n",
    "        config = self.config\n",
    "        others = config['others']\n",
    "        objects = config['objects']\n",
    "        if 'save_dir' in others:\n",
    "            metrics_log = objects['metrics_log']\n",
    "            save_path = os.path.join(others['save_dir'], 'metrics_log.json')\n",
    "            with open(save_path, 'w') as f:\n",
    "                json.dump(metrics_log, f)\n",
    "\n",
    "\n",
    "    def close(self):\n",
    "        from flash.event import close_logger\n",
    "        config = self.config\n",
    "        others = config['others']\n",
    "        objects = config['objects']\n",
    "        self.save_metrics()\n",
    "        \n",
    "        close_logger(objects['vis_tool'], others['vis_tool'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T13:18:05.403971Z",
     "start_time": "2020-01-18T13:18:05.339953Z"
    }
   },
   "source": [
    "# pytorch dependent\n",
    "class EvalProcess(Process):\n",
    "    def __init__(self, model, pre_operator=None, post_operator=None,\n",
    "                 skip_condition=None, process_name=None, mode='eval',\n",
    "                 keep_outputs=lambda iter_, num_iter, state, name:(True, str(name)+f'{iter_}', {'retain_comp_graph':False}), metrics={}):\n",
    "        # Processに移すべき？\n",
    "        self.process_name = process_name\n",
    "        # 必要？\n",
    "        self.mode = mode\n",
    "        \n",
    "        self.model = model\n",
    "        \n",
    "        self.skip_condition = skip_condition\n",
    "        self.pre_operator = pre_operator\n",
    "        self.post_operator = post_operator\n",
    "        \n",
    "        self.keep_outputs = keep_outputs\n",
    "        \n",
    "        self.metrics = metrics\n",
    "\n",
    "    def run(self, state=None, process_config={}):\n",
    "        if self.skip_condition is not None:\n",
    "            if self.skip_condition(self, state=state):\n",
    "                return None\n",
    "        \n",
    "        self.model.eval()\n",
    "        \n",
    "        data_server = self.data_server\n",
    "        params = { 'state' : state, 'iter_' : iter_, 'data_server' : data_server }\n",
    "        \n",
    "        if self.pre_operator is not None:\n",
    "            self.pre_operator(self, **params)\n",
    "            \n",
    "        Keep_outputs, output_name, outputs_type_info = self.keep_outputs(iter_, self.num_iter, state, self.process_name)\n",
    "        \"\"\"\n",
    "            original with clause as used in GPytorch\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            for inputs, size_portion in data_server.generate_inputs():\n",
    "                outputs = self(inputs, **process_config.get(\"forward_args\", {}))\n",
    "                if Keep_outputs:\n",
    "                    data_server.push(outputs, transform_info=outputs_type_info, key='outputs')\n",
    "\n",
    "        data_server.register(name_for_register=self.process_name)\n",
    "\n",
    "        if self.post_operator is not None:\n",
    "            self.post_operator(self, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T13:50:09.340552Z",
     "start_time": "2020-01-18T13:50:09.286303Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.1864)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.results['loss/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T13:25:38.470012Z",
     "start_time": "2020-01-18T13:25:38.431927Z"
    }
   },
   "outputs": [],
   "source": [
    "dw.data_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T13:19:14.375850Z",
     "start_time": "2020-01-18T13:19:14.313272Z"
    }
   },
   "outputs": [],
   "source": [
    "ep = EvalProcess(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T13:20:35.600029Z",
     "start_time": "2020-01-18T13:20:35.580804Z"
    }
   },
   "outputs": [],
   "source": [
    "ep.set_data_server(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T13:20:39.869698Z",
     "start_time": "2020-01-18T13:20:39.783849Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'iter_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-f990ec595ef7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-70555a390332>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, state, process_config)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mdata_server\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m \u001b[0;34m'state'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'iter_'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0miter_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data_server'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mdata_server\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_operator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'iter_' is not defined"
     ]
    }
   ],
   "source": [
    "ep.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_batches = len(ds.data_loader)\n",
    "grad_accumulation_steps = 1\n",
    "log_interval = 2\n",
    "\n",
    "def get_loss_from_results(results):\n",
    "    return results['loss/']\n",
    "\n",
    "import torch\n",
    "def log_training_loss(self, state, process_config={}):\n",
    "    \"\"\"\n",
    "        ### ToDo : check the following process\n",
    "    \"\"\"\n",
    "    epoch = state[\"global/epoch\"]\n",
    "    iter_ = state[\"run/iteration\"]\n",
    "    iter_ = ((iter_ - 1) % num_train_batches) // grad_accumulation_steps + 1\n",
    "    #num_iter_per_epoch = (num_train_batches - 1) // grad_accumulation_steps + 1\n",
    "\n",
    "    if iter_ % log_interval == 0:\n",
    "        results_loss = get_loss_from_results(self.data_server.results)\n",
    "        #results_loss = results['loss']\n",
    "        if isinstance(results_loss, torch.Tensor):\n",
    "            loss_val = results_loss.item()\n",
    "            print_message = \"Epoch[{}] Iteration[{}/{}] Loss: {:.3f}\".format(epoch, iter_, num_train_batches, loss_val)\n",
    "        else:\n",
    "            if isinstance(results_loss, list):\n",
    "                loss_val = { f\"({n})\" if n != \"\" else \"\":l.item() for n,l in enumerate(results_loss, 1) }\n",
    "            elif isinstance(results_loss, dict):\n",
    "                loss_val = { k:l.item() for k,l in results_loss.items() }\n",
    "            else:\n",
    "                assert False, 'Invalid type for loss'\n",
    "            print_message = f\"Epoch[{epoch}] Iteration[{iter_}/{num_train_batches}] Loss: \"+\"\".join([ f\" {k} = {v:.4f} \" for k,v in loss_val.items() ])\n",
    "            \n",
    "        print(print_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ev = Process(func=log_training_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "em.register_event(\"iter-end\", ev)\n",
    "\n",
    "em._set_data_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ignite.engine import Events\n",
    "from ignite.handlers import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "tensorboardX_flags = ['t', 'tf', 'tensorboard', 'tensorboardX']\n",
    "visdom_flags = ['v', 'vis', 'visdom']\n",
    "\n",
    "\"\"\"\n",
    "    ToDo\n",
    "        * correct tensorboard flow\n",
    "        * correct visdom flow\n",
    "        * add tensorwatch flow\n",
    "    Investigate\n",
    "    * flush setting on tdqm ?\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def create_default_events(config):\n",
    "    vis_tool = config['others']['vis_tool']\n",
    "    if vis_tool in tensorboardX_flags:\n",
    "        try:\n",
    "            from tensorboardX import SummaryWriter\n",
    "        except ImportError:\n",
    "            raise RuntimeError(\"No tensorboardX package is found. Please install with the command: \\npip install tensorboardX\")\n",
    "        log_dir = \"tf_log\"\n",
    "    elif vis_tool in visdom_flags:\n",
    "        try:\n",
    "            import visdom\n",
    "        except ImportError:\n",
    "            raise RuntimeError(\"No visdom package is found. Please install it with command: \\n pip install visdom\")\n",
    "    else:\n",
    "        if vis_tool == 'notebook':\n",
    "            from tqdm import tqdm_notebook as tqdm\n",
    "        else:\n",
    "            from tqdm import tqdm\n",
    "\n",
    "\n",
    "    objects = config['objects']\n",
    "    grad_accumulation_steps = config['others'].get('grad_accumulation_steps', 1)\n",
    "    train_loader = objects['data']['train_loader']\n",
    "    val_loader = objects['data']['val_loader']\n",
    "    eval_train_loader = objects['data'].get('eval_train_loader', None)\n",
    "    train_evaluator = objects['engine']['train_evaluator']\n",
    "    val_evaluator = objects['engine']['val_evaluator']\n",
    "    trainer = objects['engine']['trainer']\n",
    "\n",
    "    num_train_batches = len(train_loader)\n",
    "    log_interval = config['others']['log_interval']\n",
    "    \n",
    "    if vis_tool in tensorboardX_flags:\n",
    "        def create_summary_writer(log_dir):\n",
    "            writer = SummaryWriter(logdir=log_dir)\n",
    "            #data_loader_iter = iter(data_loader)\n",
    "            #x, y = next(data_loader_iter)\n",
    "            #try:\n",
    "            #    writer.add_graph(model, x)\n",
    "            #except Exception as e:\n",
    "            #    print(\"Failed to save model graph: {}\".format(e))\n",
    "        return writer\n",
    "        writer = create_summary_writer(log_dir)\n",
    "        objects['vis_tool'] = writer\n",
    "    elif vis_tool in visdom_flags:\n",
    "        vis = visdom.Visdom()\n",
    "        def create_plot_window(vis, xlabel, ylabel, title):\n",
    "            return vis.line(X=np.array([1]), Y=np.array([np.nan]), opts=dict(xlabel=xlabel, ylabel=ylabel, title=title))\n",
    "        train_loss_window = create_plot_window(vis, '#Iterations', 'Loss', 'Training Loss')\n",
    "        train_avg_loss_window = create_plot_window(vis, '#Iterations', 'Loss', 'Training Average Loss')\n",
    "        train_avg_accuracy_window = create_plot_window(vis, '#Iterations', 'Accuracy', 'Training Average Accuracy')\n",
    "        val_avg_loss_window = create_plot_window(vis, '#Epochs', 'Loss', 'Validation Average Loss')\n",
    "        objects['vis_tool'] = vis\n",
    "    else:\n",
    "        desc = \"ITERATION - loss: \"\n",
    "        pbar = tqdm(\n",
    "            initial=0, leave=False, total=len(train_loader),\n",
    "        )\n",
    "        objects['vis_tool'] = pbar\n",
    "\n",
    "    import torch\n",
    "    def log_training_loss(self, state, event_config={}):\n",
    "        \"\"\"\n",
    "            ### ToDo : check the following process\n",
    "        \"\"\"\n",
    "        epcoh = state[\"global/epoch\"]\n",
    "        iter_ = state[\"run/iteration\"]\n",
    "        iter_ = ((iter_ - 1) % num_train_batches) // grad_accumulation_steps + 1\n",
    "        #num_iter_per_epoch = (num_train_batches - 1) // grad_accumulation_steps + 1\n",
    "\n",
    "        if iter_ % log_interval == 0:\n",
    "            results = self.results\n",
    "            results_loss = results['loss']\n",
    "            if isinstance(results_loss, torch.Tensor):\n",
    "                loss_val = results_loss.item()\n",
    "                print_message = \"Epoch[{}] Iteration[{}/{}] Loss: {:.2f}\".format(epoch, iter_, num_train_batches, loss_val)\n",
    "            else:\n",
    "                if isinstance(results_loss, list):\n",
    "                    loss_val = { f\"({n})\":l.item() for n,l in enumerate(results_loss, 1) }\n",
    "                elif isinstance(results_loss, dict):\n",
    "                    loss_val = { k:l.item() for k,l in results_loss.items() }\n",
    "                else:\n",
    "                    assert False, 'Invalid type for loss'\n",
    "                print_message = f\"Epoch[{epoch}] Iteration[{iter_}/{num_train_batches}] Loss: \"+\"\".join([ f\" {k} = {v:.4f} \" for k,v in loss_val.items() ])\n",
    "\n",
    "            if vis_tool in tensorboardX_flags:\n",
    "                print(print_message, flush=True)\n",
    "                writer.add_scalar(\"training/loss\", loss_val, iter_)\n",
    "            elif vis_tool in visdom_flags:\n",
    "                \"\"\"\n",
    "                    to correct in th future\n",
    "                \"\"\"\n",
    "                print(print_message, flush=True)\n",
    "                vis.line(X=np.array([state.iteration]),\n",
    "                         Y=np.array([state.output]), update='append', win=train_loss_window)\n",
    "            else:\n",
    "                pbar.desc = print_message\n",
    "                pbar.update(log_interval)\n",
    "\n",
    "    def log_training_results(state, **kwargs):\n",
    "        if vis_tool not in tensorboardX_flags and visdom_flags not in visdom_flags:\n",
    "            pbar.refresh()\n",
    "        train_evaluator.run(train_loader if eval_train_loader is None else eval_train_loader)\n",
    "        metrics = train_evaluator.state.metrics\n",
    "        print_logs(config, state, metrics, phase='train')\n",
    "\n",
    "    def log_validation_results(state, **kwargs):\n",
    "        val_evaluator.run(val_loader)\n",
    "        metrics = val_evaluator.state.metrics\n",
    "        print_logs(config, state, metrics, phase='validation')\n",
    "        if vis_tool not in tensorboardX_flags and visdom_flags not in visdom_flags:\n",
    "            pbar.n = pbar.last_print_n = 0\n",
    "        ###\n",
    "        trainer.save_metrics()\n",
    "\n",
    "    \n",
    "\n",
    "    if \"handlers\" in config.keys():\n",
    "        handlers =  config['handlers']\n",
    "\n",
    "        if 'early_stopping' in handlers.keys():\n",
    "            hdl_early_stopping = handlers['early_stopping']\n",
    "            patience = hdl_early_stopping['patience']\n",
    "            if 'score_function' in hdl_early_stopping.keys():\n",
    "                score_function = hdl_early_stopping['score_function']\n",
    "            else:\n",
    "                score_name = hdl_early_stopping.get('score_name', 'loss')\n",
    "                score_function = lambda engine:-engine.state.metrics[score_name]\n",
    "            ES_handler = EarlyStopping(patience=patience, score_function=score_function, trainer=trainer)\n",
    "            val_evaluator.add_event_handler(Events.COMPLETED, ES_handler)\n",
    "\n",
    "        if 'checkpoint' in handlers.keys():\n",
    "            hdl_checkpoint = handlers['checkpoint']\n",
    "            save_interval = hdl_checkpoint.get('save_interval',1)\n",
    "            n_saved = hdl_checkpoint.get('n_saved', float('inf'))\n",
    "            target_models = hdl_checkpoint.get('target_models', list(objects['models'].keys()))\n",
    "            save_target_models = { model_name : objects['models'][model_name] for model_name in target_models }\n",
    "            model_name_prefix = hdl_checkpoint.get('prefix', \"\")\n",
    "            model_name = hdl_checkpoint.get('name', \"model\")\n",
    "            model_dir = hdl_checkpoint.get('save_dir', \"checkpoints\")\n",
    "\n",
    "            #model = config['objects']['model']\n",
    "            MC_handler = ModelCheckpoint(model_dir, model_name_prefix, save_interval=save_interval, n_saved=n_saved, create_dir=True)\n",
    "            trainer.add_event_handler(Events.EPOCH_COMPLETED, MC_handler, save_target_models)#{model_name : model})\n",
    "\n",
    "\n",
    "def print_logs(config, state, metrics, phase):\n",
    "    vis_tool = config['others']['vis_tool']\n",
    "    objects = config['objects']\n",
    "    metrics_log = objects.get('metrics_log', None)\n",
    "\n",
    "    if metrics_log is not None:\n",
    "        for name, value in metrics.items():\n",
    "            metrics_log[f'{phase}/{name}'].append(value)\n",
    "\n",
    "    epoch = state.epoch\n",
    "    \n",
    "    print_message = f\"Epoch: {epoch} :: {phase:^12} results - \" +\\\n",
    "        \" \".join([f\"{name}: {value:.4f}\" for name, value in metrics.items() if isinstance(value, float)])\n",
    "    \n",
    "    if vis_tool in tensorboardX_flags:\n",
    "        print(print_message, flush=True)\n",
    "        for name, val in [(\"avg_loss\", avg_nll), (\"avg_accuracy\", avg_accuracy)]:\n",
    "            writer.add_scalar(f\"{phase}/{name}\", val, epoch)\n",
    "    elif vis_tool in visdom_flags:\n",
    "        print(print_message, flush=True)\n",
    "        for val, win in [(avg_accuracy, val_avg_accuracy_window), (avg_nll, val_avg_loss_window)]:\n",
    "            vis.line(X=np.array([epoch]), Y=np.array([val]), win=win, update='append')\n",
    "    else:\n",
    "        from tqdm import tqdm\n",
    "        tqdm.write(print_message)\n",
    "\n",
    "    \n",
    "def close_logger(vis_tool, vis_tool_name):\n",
    "    if vis_tool_name in tensorboardX_flags:\n",
    "        writer = vis_tool\n",
    "        writer.close()\n",
    "    elif vis_tool_name in visdom_flags:\n",
    "        vis = vis_tool\n",
    "        pass\n",
    "    else:\n",
    "        pbar = vis_tool\n",
    "        pbar.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
